{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "### Parsing Flats:",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Description:\n",
    "\n",
    "In this project, I want to combine several components at once, namely:\n",
    "- Parse data from a website about property sales;\n",
    "- Visualize various metrics that would be interesting to track;\n",
    "- Systematize this entire cycle.\n",
    "\n",
    "Roughly, this project consists of the following parts:\n",
    "- Parsing -> sending data to the database -> data visualization, with all of this happening in a systematic way.\n",
    "\n",
    "This notebook will contain the code and thoughts throughout my work. The technologies I will use are:\n",
    "- Python and libraries;\n",
    "- Clickhouse;\n",
    "- Superset;\n",
    "- Airflow;\n",
    "- Docker."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from hyper.contrib import HTTP20Adapter\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from time import sleep\n",
    "from airflow.models import Variable\n",
    "from datetime import datetime, timedelta\n",
    "from clickhouse_driver import Client\n",
    "import telegram\n",
    "import emoji # For the special mission\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Parameters for Airflow\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'retries': 2,\n",
    "    'retry_delay': timedelta(minutes=3),\n",
    "    'start_date': datetime(2022, 9, 3),\n",
    "}\n",
    "schedule_interval = \"00 22 * * 4\"\n",
    "\n",
    "# Configs for Telegram Bot and Clickhouse\n",
    "client = Client(host=Variable.get(\"CLICKHOUSE_HOST\"))\n",
    "my_token = Variable.get(\"TG_TOKEN\")\n",
    "bot = telegram.Bot(token=my_token)\n",
    "chat_id = Variable.get(\"CHAT_ID_MOSCOW_FLATS\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What I will parse:\n",
    "1. The URL;\n",
    "2. Price per square meter;\n",
    "3. Cost per square meter;\n",
    "4. Total apartment price;\n",
    "5. Distance from the metro.\n",
    "\n",
    "Warning:\n",
    "- The data is very messy during collection, so it has to be cleaned at every stage."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parce_vacancies():\n",
    "    lst_links, lst_square, lst_price, lst_subway, lst_description, lst_minutes = [], [], [], [], [], []\n",
    "\n",
    "    for page in range(1, 99):\n",
    "        print(emoji.emojize(f'Parsing {page} page :monkey:'))\n",
    "        full_url = f\"https://www.avito.ru/moskva/kvartiry/prodam-ASgBAgICAUSSA8YQ?cd=1&p={page}\"\n",
    "        source = requests.Session()\n",
    "        source.mount('https://', HTTP20Adapter())#adapter so that the server does not perceive us as a bot\n",
    "        response = source.get(full_url)\n",
    "        sleep(7)\n",
    "        response.encoding = 'utf-8'\n",
    "        soup = bs(response.text, 'lxml')\n",
    "\n",
    "        all_flats = soup.findAll(\"div\", class_=\"iva-item-content-rejJg\")\n",
    "\n",
    "        for flat in all_flats:\n",
    "\n",
    "            # Link to the apartment:\n",
    "            var_link = flat.find(\"a\",\n",
    "                                 \"link-link-MbQDP link-design-default-_nSbv title-root-zZCwT iva-item-title-py3i_ title-listRedesign-_rejR title-root_maxHeight-X6PsH\")\n",
    "            if var_link is not None:\n",
    "                local_var_link = \"https://www.avito.ru\" + var_link.get(\"href\")\n",
    "                lst_links.append([local_var_link])\n",
    "            else:\n",
    "                lst_links.append([None])\n",
    "\n",
    "            # Price per square meter:\n",
    "            var_square = flat.find(\"span\",\n",
    "                                   class_=\"price-noaccent-X6dOy price-normalizedPrice-PplY9 text-text-LurtD text-size-s-BxGpL\")\n",
    "            if var_square is not None:\n",
    "                var = flat.find(\"span\",\n",
    "                                class_=\"price-noaccent-X6dOy price-normalizedPrice-PplY9 text-text-LurtD text-size-s-BxGpL\").text\n",
    "                correct_number_square_price = \"\"\n",
    "                for var_square_circle in var:\n",
    "                    if var_square_circle.isdigit():\n",
    "                        correct_number_square_price += var_square_circle\n",
    "                # We remove the last digit since the value there is squared:\n",
    "                correct_number_square_price = correct_number_square_price.replace(correct_number_square_price[-1], \"\")\n",
    "                lst_square.append(correct_number_square_price)\n",
    "            else:\n",
    "                lst_square.append(None)\n",
    "\n",
    "            # Full number\n",
    "            var_full_price = flat.find(\"span\", class_=\"price-text-_YGDY text-text-LurtD text-size-s-BxGpL\")\n",
    "            if var_full_price is not None:\n",
    "                full_price = var_full_price.text\n",
    "                correct_number_full_price = \"\"\n",
    "                # We leave only the number:\n",
    "                for var_full_price_circle in full_price:\n",
    "                    if var_full_price_circle.isdigit():\n",
    "                        correct_number_full_price += var_full_price_circle\n",
    "                lst_price.append(correct_number_full_price)\n",
    "            else:\n",
    "                lst_price.append(None)\n",
    "\n",
    "            # Metro station\n",
    "            var_subway = flat.find('div', class_=\"geo-georeferences-SEtee text-text-LurtD text-size-s-BxGpL\")\n",
    "            if var_subway is not None:\n",
    "                subway_name = var_subway.text\n",
    "                subway_full = \"\"\n",
    "                for var_subway_circle in subway_name:\n",
    "                    if var_subway_circle.isalpha() or var_subway_circle == \" \" or var_subway_circle == \"-\":\n",
    "                        subway_full += var_subway_circle\n",
    "                    else:\n",
    "                        break\n",
    "                # I write if for those cases when the name of the metro includes from and to:\n",
    "                if (subway_full[-1] == \"т\" and subway_full[-2] == \"о\") or (\n",
    "                        subway_full[-1] == \"о\" and subway_full[-2] == \"д\"):\n",
    "                    subway_full = subway_full[0:-2]\n",
    "                lst_subway.append(subway_full)\n",
    "            else:\n",
    "                lst_subway.append(None)\n",
    "\n",
    "            # Distance to metro:\n",
    "            var_minutes = flat.find(\"span\", class_=\"geo-periodSection-bQIE4\")\n",
    "            if var_minutes is not None:\n",
    "                var_minutes_text = var_minutes.text\n",
    "                var_minutes_full = \"\"\n",
    "                for var_minute_circle in var_minutes_text:\n",
    "                    if var_minute_circle == '–' or var_minute_circle.isdigit():\n",
    "                        var_minutes_full += var_minute_circle\n",
    "                lst_minutes.append(var_minutes_full)\n",
    "            else:\n",
    "                lst_minutes.append(None)\n",
    "\n",
    "    full_df = pd.DataFrame(\n",
    "        data={\"square_price\": lst_square, \"full_price\": lst_price, \"subway\": lst_subway, \"links\": lst_links,\n",
    "              'destination_from_nearest_subway': lst_minutes})\n",
    "\n",
    "    return full_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_df = parce_vacancies()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "I'll create a copy of df so that if I transform any column, I can return to the original dataframe:",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_df_test = full_df.copy()\n",
    "full_df_test.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "Next, I will filter the data frame from empty values, change the data types, and correct all the shortcomings with links:",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def filter_df(df):\n",
    "    df = df.drop_duplicates(\n",
    "        subset=\"links\")  # Sometimes duplicates appear because the site 'dynamically' moves to the next page\n",
    "    df = df.dropna()\n",
    "    df[[\"square_price\", \"full_price\"]] = df[[\"square_price\", \"full_price\"]].astype(\"int64\")\n",
    "    df[[\"subway\", \"links\", \"destination_from_nearest_subway\"]] = df[\n",
    "        [\"subway\", \"links\", \"destination_from_nearest_subway\"]].astype(str)\n",
    "    df.links = df.links.str.replace(\"[\", \"\")\n",
    "    df.links = df.links.str.replace(\"]\", \"\")\n",
    "    df.links = df.links.str.replace(\"'\",\"\")\n",
    "\n",
    "    df[\"quantity_of_metres\"] = (df[\"full_price\"] / df[\"square_price\"]).round()\n",
    "    df[\"date_of_parsing\"] = datetime.today().strftime('%Y-%m-%d')\n",
    "    df[\"date_of_parsing\"] = pd.to_datetime(df[\"date_of_parsing\"])\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_df_test = filter_df(full_df_test)\n",
    "full_df_test.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def uncommon_values(df_new):\n",
    "\n",
    "    # We extract all records from the table and create a new dataframe:\n",
    "    df_old = client.execute(\"Select * from avito_flats\")\n",
    "    df_old = pd.DataFrame(columns=[\"square_price\", \"full_price\", \"subway\", \"links\", \"destination_from_nearest_subway\", \"quantity_of_metres\", \"date_of_parsing\"],\n",
    "                          data=df_old)\n",
    "    df_new_values = df_new.merge(df_old,on=\"links\",how=\"left\",indicator=True).loc[lambda x: x[\"_merge\"] == 'left_only']\n",
    "    df_new_values = df_new_values.drop([\"square_price_y\",\"full_price_y\",\"subway_y\",\"destination_from_nearest_subway_y\",\"quantity_of_metres_y\", \"date_of_parsing_y\", \"_merge\"],axis=1)\n",
    "    df_new_values = df_new_values.rename(columns={\"square_price_x\":\"square_price\", \"full_price_x\":\"full_price\",\"subway_x\":\"subway\",\"destination_from_nearest_subway_x\":\"destination_from_nearest_subway\",\"quantity_of_metres_x\":\"quantity_of_metres\",\"date_of_parsing_x\":\"date_of_parsing\"})\n",
    "\n",
    "    return df_new_values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_df_new_values = uncommon_values(full_df_test)\n",
    "full_df_new_values.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "Now it's worth checking that everything works, and this can be done using inner join, because as we know, it searches for common elements, so if it returns an empty data frame, then the selected data frame contains only new values:",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "click_data = client.execute(\"Select * from avito_flats\")\n",
    "click_data = pd.DataFrame(columns=[\"square_price\", \"full_price\", \"subway\", \"links\", \"destination_from_nearest_subway\", \"quantity_of_metres\", \"date_of_parsing\"],\n",
    "                      data=click_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_df_new_values.merge(click_data,how=\"inner\",on=\"links\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": "We made sure that everything is fine and now we can continue, but before that we should immediately add new data to the database:",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def to_clickhouse(df):\n",
    "    client.execute(\"INSERT INTO default.avito_flats VALUES\", df.to_dict(orient=\"records\"))\n",
    "    client.execute('OPTIMIZE TABLE avito_flats DEDUPLICATE BY links')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_clickhouse(full_df_new_values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How will cheap apartments be selected?\n",
    "- The approach is as follows: first, we will look at the value of the 15th quantile at each metro station and then filter all values by it, thereby being able to select cheap apartments by metro station. I will also take apartments that are within 10 minutes of the metro."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def cheap_flats(df):\n",
    "    def q15(x):\n",
    "        return x.quantile(0.15)\n",
    "\n",
    "    # I create a data frame for each station with the 10th percentile for each metric\n",
    "    metro_10_percentile = df.groupby(\"subway\", as_index=False).agg({\"full_price\": q15, \"square_price\": q15}).rename(\n",
    "        columns={\"full_price\": \"full_price_10_percentile\", \"square_price\": \"square_price_10_percentile\"}).sort_values(\n",
    "        \"square_price_10_percentile\", ascending=False)\n",
    "\n",
    "    needed_flats = df.query(\"destination_from_nearest_subway in ('5','6-10')\")\n",
    "    both_frames = needed_flats.merge(metro_10_percentile, how=\"left\", on=\"subway\")\n",
    "    cheep_flats = both_frames.query(\n",
    "        \"square_price <= square_price_10_percentile and full_price <= full_price_10_percentile\").drop_duplicates(\n",
    "        subset=\"links\")\n",
    "    cheep_flats = cheep_flats[\n",
    "        [\"square_price\", \"full_price\", \"subway\", \"links\", \"destination_from_nearest_subway\", \"quantity_of_metres\"]]\n",
    "\n",
    "    return cheep_flats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "needed_df = cheap_flats(full_df_test)\n",
    "needed_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def send_cheap_flats(df):\n",
    "    for index, row in df.iterrows():\n",
    "        sleep(7)\n",
    "        current_row = f\"A great apartment deal just appeared on the website:\\n\" \\\n",
    "                      f\"- Price per square meter: {row[0]};\\n\" \\\n",
    "                      f\"- Total price = {row[1]};\\n\" \\\n",
    "                      f\"- Area = {row[5]} square meters;\\n\" \\\n",
    "                      f\"- Located near metro station = {row[2]} ({row[4]} minutes from the metro).\\n\" \\\n",
    "                      f\"If you're interested in this offer, follow the link: {row[3]}\"\n",
    "        bot.sendMessage(chat_id=chat_id, text=current_row)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "send_cheap_flats(needed_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
